

## Network

```bash

# Do 1 target of a time (Start with AD)
# Do a TCP port scan
sudo nmap -p- -sS -sV -sC -Pn -v --open -oN nmap/150.nmap 192.168.x.x

# Do a scan of top 90% most common UDP ports (Most likely to find SNMP)
sudo nmap -sU --max-scan-delay 10ms --max-retries 1 --max-rtt-timeout 200ms -v --top-ports 2000 192.168.x.x

# Identify services (Including possibly web page title + exploit)
# Google + exploit
# Searchsploit

# If host has internal network interface set up ligolo
# Scan the internal network
sudo nmap -p- -sS -sV -sC -Pn --open -oN nmap/internal.nmap -iL info/targets.internal

```

## Web

```bash

# Fuzz directories
# Doing with / on the end might force a 301 instead of a 200 but also makes you miss out on potential files!!
ffuf -w /usr/share/wordlists/seclists/Discovery/Web-Content/directory-list-2.3-small.txt -u http://192.168.x.x:port/FUZZ

# Fuzz directories #2 (Helped find .git repos)
dirsearch -u target.url -t 50 -i 200

# Example of recursive Directory discovery
ffuf -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-small.txt -u <http://target_url/FUZZ> -recursion -recursion-depth 3 -e .php -v

# FUZZ for subdomains
ffuf -u http://target.url -H "Host: FUZZ.target.url" -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-small.txt -fc 301

# FUZZ for subdomains #2 (Problem may be with the host name and the /etc/hosts file so use IP instead!! And try different lists!!)
ffuf -w /usr/share/wordlists/SecLists/Discovery/DNS/bitquark-subdomains-top100000.txt -H "Host:FUZZ.target.com" -u 'http://10.10.11.68' -fc 301

# Run whatweb for more info about technologies used
whatweb http://192.168.x.x:port

# Run nikto scan
nikto -url http://192.168.x.x:port

# Check Wappalyzer

# Use wpscan
wpscan --url http://192.168.x.x --enumerate p --plugins-detection aggressive -o info/wpscan

# Identify services (Including possibly web page title + exploit)
# Google + exploit
# Searchsploit

```

## AD

```bash

# Run kerbrute User Enumeration (Requires access to the DC which is probably on the internal network)
./kerbrute userenum /usr/share/wordlists/seclists/Usernames/Names/names.txt --dc 192.168.x.x -d oscp.exam

# Run bloodhound
# From Kali
sudo bloodhound-python -u 'user' -p 'password' -ns x.x.x.x -d oscp.local -c all

# From netexec


# From Windows
# Import the module
powershell -ep bypass
Import-Module .\Sharphound.ps1

# We must first run invoke-bloodhound
# Get-help shows more info
Get-Help Invoke-BloodHound

# Collect all data available
Invoke-BloodHound -CollectionMethod All -OutputDirectory C:\users\public\ -OutputPrefix "corp-audit"

# Start bloodhound
sudo neo4j start 
bloodhound

# Save down all computers and users
MATCH (m:User) RETURN m
MATCH (m:Computer) RETURN m

# Good to do/look for
Mark users/computers owned

Low hanging fruits
		Find all Domain Admins
    Find Workstations where Domain Users can RDP
    Find Servers where Domain Users can RDP
    Find Computers where Domain Users are Local Admin
    Shortest Path to Domain Admins from Owned Principals
	
# inveigh - Like responder but for Windows


```

## SMB

```bash

# Enumerate shares
netexec smb 172.16.194.10-13 172.16.194.82-83 -u joe -p "Flowers1" -d medtech.com --shares

# Check null auth
smbclient -U "" -L \\\\192.168.x.x

# Enum4linux
enum4linux -a 192.168.x.x

# Go through the files in a share
smbclient -p 445 //172.16.131.21/share -U user@oscp.exam --password='DRtajyCwcbWvH/9'
smbclient \\\\192.168.228.175\\Password\ Audit -U "resourced.local\V.Ventz"

# Download all files
recurse on
prompt off
mget *

# Collect hashes with scf file
# Run responder
# Upload the exploit file, wich will send back the NTLMv2 hash to responder
Upload @pen.scf



```

## RPC

```bash

# Check null auth
rpcclient -U "" 192.168.x.x


```